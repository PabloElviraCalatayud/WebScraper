Repository,Title,Authors,Abstract,DOI
"PubMed","Meta-Learning for Fast Adaptation in Intent Inferral on a Robotic Hand Orthosis for Stroke.","Pedro Leandro La Rotta; Jingxi Xu; Ava Chen; Lauren Winterbottom; Wenxi Chen; Dawn Nilsen; Joel Stein; Matei Ciocarlie","We propose MetaEMG, a meta-learning approach for fast adaptation in intent inferral on a robotic hand orthosis for stroke. One key challenge in machine learning for assistive and rehabilitative robotics with disabled-bodied subjects is the difficulty of collecting labeled training data. Muscle tone and spasticity often vary significantly among stroke subjects, and hand function can even change across different use sessions of the device for the same subject. We investigate the use of meta-learning to mitigate the burden of data collection needed to adapt high-capacity neural networks to a new session or subject. Our experiments on real clinical data collected from five stroke subjects show that MetaEMG can improve the intent inferral accuracy with a small session- or subject-specific dataset and very few fine-tuning epochs. To the best of our knowledge, we are the first to formulate intent inferral on stroke subjects as a meta-learning problem and demonstrate fast adaptation to a new session or subject for controlling a robotic hand orthosis with EMG signals. ","10.1109/iros58592.2024.10801596"
"PubMed","Deep Learning-Based Subject Independent Human Activity Recognition using Smart Lacelock Data.","Najmeh Movahhed Neya; Edward Sazonov; Xiangrong Shen","Human Activity Recognition (HAR) field is rapidly growing and the classification of human activities based on sensor data is crucial for applications in healthcare, rehabilitation and numerous other sectors. In this paper we use a novel device and attempt Deep Learning-based HAR from the device data.Typically, sensor-based HAR tasks use data from accelerometer and gyroscope within Inertial Measurement Units (IMU). But in this work we use the data from Smart Lacelock device, which is home to IMU and loadcell, introducing an additional sensor, aimed at complementing IMU data. This novel device ensures user comfort by attaching to the user's shoe as a shoelace tensioning device without any shoe modification. The data for this study was collected by the UA HuB-Robotics Lab from eight participants.Using this comprehensive dataset, we propose a CNN based model to classify activities such as walking, stair climbing, and stair descending. The model comprises three consecutive CNN blocks, and within each block there is a convolutional layer, a max-pooling layer, a Rectified Linear Unit (ReLU) layer, and a normalization layer. The model has a dropout and a flatten layer right after the third block of CNN and concludes with 2 dense layers. Our model achieves an average recognition accuracy of 98.4% using the leave-one-out (L1O) technique.In this work Smart Lacelock device demonstrated feasibility in recognition of a set of human activities and the results support further investigation of its applications in HAR. ","10.1109/EMBC53108.2024.10781739"
"PubMed","Adaptive formation learning control for cooperative AUVs under complete uncertainty.","Emadodin Jandaghi; Mingxi Zhou; Paolo Stegagno; Chengzhi Yuan","This paper addresses the critical need for adaptive formation control in Autonomous Underwater Vehicles (AUVs) without requiring knowledge of system dynamics or environmental data. Current methods, often assuming partial knowledge like known mass matrices, limit adaptability in varied settings. We proposed two-layer framework treats all system dynamics, including the mass matrix, as entirely unknown, achieving configuration-agnostic control applicable to multiple underwater scenarios. The first layer features a cooperative estimator for inter-agent communication independent of global data, while the second employs a decentralized deterministic learning (DDL) controller using local feedback for precise trajectory control. The framework's radial basis function neural networks (RBFNN) store dynamic information, eliminating the need for relearning after system restarts. This robust approach addresses uncertainties from unknown parametric values and unmodeled interactions internally, as well as external disturbances such as varying water currents and pressures, enhancing adaptability across diverse environments. Comprehensive and rigorous mathematical proofs are provided to confirm the stability of the proposed controller, while simulation results validate each agent's control accuracy and signal boundedness, confirming the framework's stability and resilience in complex scenarios. ","10.3389/frobt.2024.1491907"
"PubMed","Does the transfer of knowledge from the pioneer generation to the second-generation speed-up the learning curve of robot-assisted partial nephrectomies? TRANSFER trial (UroCCR n°83).","Louis Vignot; Zine-Eddine Khene; Adil Mellouki; Arnoult Morrone; Jean-Christophe Bernhard; Karim Bensalah; Daniel Chevallier; Nicolas Doumerc; Morgan Roupret; Francois-Xavier Nouhaud; Cédric Lebacle; Jean-Alexandre Long; Pierre Pillot; Xavier Tillou; Brannwel Tibi; Matthieu Durand; Younes Ahallal; Imad Bentellis","The objective is to compare the learning curves between two pioneer and three second-generation surgeons for RAPN in terms of WIT, CD and positive surgical margins. The charts of consecutive RAPNs of three centres were reviewed from the UroCCR prospective database. The experience was assessed by a regression model for each group. There was a univariate analysis on three consecutive sequences of 15 procedures. The learning speed for WIT was explored graphically by polynomial regression after cubic splines. Finally, CUSUM charts were obtained. There were 1203 RAPN in the pioneer group and 119 performed by second-generation surgeons. There was a significant difference in the distribution of tumour size (p < 0.001) and the RENAL score (p < 0.001). The operative time was longer in the first group (p > 0.001). Independent factors for a higher WIT were the second group (p < 0.001), higher experience (p < 0.001) the collinearity between the group and experience (p < 0.001), the RENAL score (p < 0.001) and blood loss (p < 0.001). Adjusted Loess regressions showed a plateau of WIT at 400 procedures for the pioneers and a significant decrease at 20 procedures for the second generation. CUSUM chart analysis showed a 'staircase' pattern of the learning process, with three major steps at 150, 200 and 300 procedures. The major limitation is the difference in sample size between the two arms. Learning curve patterns would reflect a transfer of knowledge to the second-generation, as opposed to the establishment of standards by the pioneers. ","10.1002/bco2.477"
"PubMed","RL-QPSO net: deep reinforcement learning-enhanced QPSO for efficient mobile robot path planning.","Yang Jing; Li Weiya","Path planning in complex and dynamic environments poses a significant challenge in the field of mobile robotics. Traditional path planning methods such as genetic algorithms, Dijkstra's algorithm, and Floyd's algorithm typically rely on deterministic search strategies, which can lead to local optima and lack global search capabilities in dynamic settings. These methods have high computational costs and are not efficient for real-time applications. To address these issues, this paper presents a Quantum-behaved Particle Swarm Optimization model enhanced by deep reinforcement learning (RL-QPSO Net) aimed at improving global optimality and adaptability in path planning. The RL-QPSO Net combines quantum-inspired particle swarm optimization (QPSO) and deep reinforcement learning (DRL) modules through a dual control mechanism to achieve path optimization and environmental adaptation. The QPSO module is responsible for global path optimization, using quantum mechanics to avoid local optima, while the DRL module adjusts strategies in real-time based on environmental feedback, thus enhancing decision-making capabilities in complex high-dimensional scenarios. Experiments were conducted on multiple datasets, including Cityscapes, NYU Depth V2, Mapillary Vistas, and ApolloScape, and the results showed that RL-QPSO Net outperforms traditional methods in terms of accuracy, computational efficiency, and model complexity. This method demonstrated significant improvements in accuracy and computational efficiency, providing an effective path planning solution for real-time applications in complex environments for mobile robots. In the future, this method could be further extended to resource-limited environments to achieve broader practical applications. ","10.3389/fnbot.2024.1464572"
"PubMed","The Transformative Impact of AI, Extended Reality, and Robotics in Interventional Radiology: Current Trends and Applications.","Katelyn Vlastaris; Annabelle Alrez; Samantha Friedland; Antonina Randazzo; Rayan Abboud; Charles Martin","Interventional Radiology is at the forefront of integrating advanced imaging techniques and minimally-invasive procedures to enhance patient care. The advent of Digital Health Technologies (DHTs), including artificial intelligence (AI), robotics, and extended reality (XR), is revolutionizing healthcare, particularly in IR due to its reliance on innovative technology and advanced imaging. Since 2016, the proportion of these DHT-related publications in IR has consistently increased. The proportion of AI-related studies published in IR was 69% higher than in surgery, XR-related studies were 94% higher, and robotics studies were 192% higher, indicating a more rapid growth rate in IR compared to surgery. This article explores the transformative impact of these technologies on IR, emphasizing their potential to enhance precision, efficiency, and patient outcomes. Despite the promising advancements, there is a lack of standardization and clinical consensus on the optimal use of DHTs in IR. The variability in IR procedures and imaging systems across hospitals complicates the standardization of workflows and comparison of studies. This underscores the importance of integrating DHTs as aids to IR practitioners rather than replacement, ensuring that these technologies enhance both clinical and procedural practice. ","10.1016/j.tvir.2024.101003"
"PubMed","CabbageNet: Deep Learning for High-Precision Cabbage Segmentation in Complex Settings for Autonomous Harvesting Robotics.","Yongqiang Tian; Xinyu Cao; Taihong Zhang; Huarui Wu; Chunjiang Zhao; Yunjie Zhao","Reducing damage and missed harvest rates is essential for improving efficiency in unmanned cabbage harvesting. Accurate real-time segmentation of cabbage heads can significantly alleviate these issues and enhance overall harvesting performance. However, the complexity of the growing environment and the morphological variability of field-grown cabbage present major challenges to achieving precise segmentation. This study proposes an improved YOLOv8n-seg network to address these challenges effectively. Key improvements include modifying the baseline model's final C2f module and integrating deformable attention with dynamic sampling points to enhance segmentation performance. Additionally, an ADown module minimizes detail loss from excessive downsampling by using depthwise separable convolutions to reduce parameter count and computational load. To improve the detection of small cabbage heads, a Small Object Enhance Pyramid based on the PAFPN architecture is introduced, significantly boosting performance for small targets. The experimental results show that the proposed model achieves a Mask Precision of 92.2%, Mask Recall of 87.2%, and Mask mAP50 of 95.1%, while maintaining a compact model size of only 6.46 MB. These metrics indicate superior accuracy and efficiency over mainstream instance segmentation models, facilitating real-time, precise cabbage harvesting in complex environments. ","10.3390/s24248115"
"PubMed","Editorial: Vision, learning, and robotics: AI for plants in the 2020s.","Zhenghong Yu; Luca Iocchi; Jeffrey Too Chuan Tan; Huabing Zhou; Changcai Yang; Hao Lu","","10.3389/fpls.2024.1539626"
"PubMed","Trajectory Tracking Control for Robotic Manipulator Based on Soft Actor-Critic and Generative Adversarial Imitation Learning.","Jintao Hu; Fujie Wang; Xing Li; Yi Qin; Fang Guo; Ming Jiang","In this paper, a deep reinforcement learning (DRL) approach based on generative adversarial imitation learning (GAIL) and long short-term memory (LSTM) is proposed to resolve tracking control problems for robotic manipulators with saturation constraints and random disturbances, without learning the dynamic and kinematic model of the manipulator. Specifically, it limits the torque and joint angle to a certain range. Firstly, in order to cope with the instability problem during training and obtain a stability policy, soft actor-critic (SAC) and LSTM are combined. The changing trends of joint position over time are more comprehensively captured and understood by employing an LSTM architecture designed for robotic manipulator systems, thereby reducing instability during the training of robotic manipulators for tracking control tasks. Secondly, the obtained policy by SAC-LSTM is used as expert data for GAIL to learn a better control policy. This SAC-LSTM-GAIL (SL-GAIL) algorithm does not need to spend time exploring unknown environments and directly learns the control strategy from stable expert data. Finally, it is demonstrated by the simulation results that the end effector of the robot tracking task is effectively accomplished by the proposed SL-GAIL algorithm, and more superior stability is exhibited in a test environment with interference compared with other algorithms. ","10.3390/biomimetics9120779"
"PubMed","Predictive Capacities of a Machine Learning Decision Tree Model Created to Analyse Feasibility of an Open or Robotic Kidney Transplant.","Alessandro Martinino; Ojus Khanolkar; Erdem Koyuncu; Egor Petrochenkov; Giulia Bencini; Joanna Olazar; Pierpaolo Di Cocco; Jorge Almario-Alvarez; Mario Spaggiari; Enrico Benedetti; Ivo Tzvetanov","Machine learning has emerged as a potent tool in healthcare. A decision tree model was built to improve the decision-making process when determining the optimal choice between an open or robotic surgical approach for kidney transplant. 822 patients (OKT) and 169 (RKT) underwent kidney transplantation at our centre during the study period. A decision tree model was built in a two-step process consisting of: (1) Creating the model on the training data and (2) testing the predictive capabilities of the model using the test data. Our model correctly predicted an OKT in 148 patients out of 161 test cases who received an OKT (accuracy 91%) and predicted an RKT in 19 out of 25 test cases of patients receiving an RKT (accuracy 76%). Our model represents the inaugural data-driven model that furnishes concrete insights for the discernment between employing robotic and open surgery techniques. ","10.1002/rcs.70035"
"PubMed","Optimized inverse kinematics modeling and joint angle prediction for six-degree-of-freedom anthropomorphic robots with Explainable AI.","Rakesh Chandra Joshi; Jaynendra Kumar Rai; Radim Burget; Malay Kishore Dutta","Inverse kinematics, crucial in robotics, involves computing joint configurations to achieve specific end-effector positions and orientations. This task is particularly complex for six-degree-of-freedom (six-DoF) anthropomorphic robots due to complicated mathematical equations, nonlinear behaviours, multiple valid solutions, physical constraints, non-generalizability and computational demands. The primary contribution of this work is to address the complex inverse kinematics problem for six-DoF anthropomorphic robots through the systematic exploration of AI models. This study involves rigorous evaluation and Bayesian optimization for hyperparameter tuning to identify the optimal regressor, balancing both accuracy and computational efficiency. Utilizing five-fold cross-validation on a publicly available dataset, the selected model demonstrates exceptional performance in predicting six joint angles for end effector configuration, yielding an average mean square error of 1.934 × 10-3 to 3.522 × 10-3. Its computational efficiency, with a prediction time of approximately 1.25 ms per sample, makes it a practical choice. Additionally, the study employs Explainable AI, using SHAP (SHapley Additive exPlanations) analysis to gain an understanding of feature importance. This analysis not only enhances model interpretability but also reaffirms the efficacy in this challenging multi-input multi-output predictive task. This research advances state-of-the-art models and neural networks by prioritizing computational efficiency alongside accuracy-a critical yet often overlooked factor. Pioneering a significant advancement in anthropomorphic robot kinematics, it balances accuracy and efficiency, offering practical robotic automation solutions. ","10.1016/j.isatra.2024.12.008"
"PubMed","AI technology to support adaptive functioning in neurodevelopmental conditions in everyday environments: a systematic review.","Nina Perry; Carter Sun; Martha Munro; Kelsie A Boulton; Adam J Guastella","Supports for adaptive functioning in individuals with neurodevelopmental conditions (NDCs) is of umost importance to long-term outcomes. Artificial intelligence (AI)-assistive technologies has enormous potential to offer efficient, cost-effective, and personalized solutions to address these challenges, particularly in everday environments. This systematic review examines the existing evidence for using AI-assistive technologies to support adaptive functioning in people with NDCs in everyday settings. Searches across six databases yielded 15 studies meeting inclusion criteria, focusing on robotics, phones/computers and virtual reality. Studies most frequently recruited children diagnosed with autism and targeted social skills (47%), daily living skills (26%), and communication (16%). Despite promising results, studies addressing broader transdiagnostic needs across different NDC populations are needed. There is also an urgent need to improve the quality of evidence-based research practices. This review concludes that AI holds enormous potential to support adaptive functioning for people with NDCs and for personalized health support. This review underscores the need for further research studies to advance AI technologies in this field. ","10.1038/s41746-024-01355-7"
"PubMed","Benefits and harms associated with the use of AI-related algorithmic decision-making systems by healthcare professionals: a systematic review.","Christoph Wilhelm; Anke Steckelberg; Felix G Rebitschek","Despite notable advancements in artificial intelligence (AI) that enable complex systems to perform certain tasks more accurately than medical experts, the impact on patient-relevant outcomes remains uncertain. To address this gap, this systematic review assesses the benefits and harms associated with AI-related algorithmic decision-making (ADM) systems used by healthcare professionals, compared to standard care. In accordance with the PRISMA guidelines, we included interventional and observational studies published as peer-reviewed full-text articles that met the following criteria: human patients; interventions involving algorithmic decision-making systems, developed with and/or utilizing machine learning (ML); and outcomes describing patient-relevant benefits and harms that directly affect health and quality of life, such as mortality and morbidity. Studies that did not undergo preregistration, lacked a standard-of-care control, or pertained to systems that assist in the execution of actions (e.g., in robotics) were excluded. We searched MEDLINE, EMBASE, IEEE Xplore, and Google Scholar for studies published in the past decade up to 31 March 2024. We assessed risk of bias using Cochrane's RoB 2 and ROBINS-I tools, and reporting transparency with CONSORT-AI and TRIPOD-AI. Two researchers independently managed the processes and resolved conflicts through discussion. This review has been registered with PROSPERO (CRD42023412156) and the study protocol has been published. Out of 2,582 records identified after deduplication, 18 randomized controlled trials (RCTs) and one cohort study met the inclusion criteria, covering specialties such as psychiatry, oncology, and internal medicine. Collectively, the studies included a median of 243 patients (IQR 124-828), with a median of 50.5% female participants (range 12.5-79.0, IQR 43.6-53.6) across intervention and control groups. Four studies were classified as having low risk of bias, seven showed some concerns, and another seven were assessed as having high or serious risk of bias. Reporting transparency varied considerably: six studies showed high compliance, four moderate, and five low compliance with CONSORT-AI or TRIPOD-AI. Twelve studies (63%) reported patient-relevant benefits. Of those with low risk of bias, interventions reduced length of stay in hospital and intensive care unit (10.3 vs. 13.0 days, p = 0.042; 6.3 vs. 8.4 days, p = 0.030), in-hospital mortality (9.0% vs. 21.3%, p = 0.018), and depression symptoms in non-complex cases (45.1% vs. 52.3%, p = 0.03). However, harms were frequently underreported, with only eight studies (42%) documenting adverse events. No study reported an increase in adverse events as a result of the interventions. The current evidence on AI-related ADM systems provides limited insights into patient-relevant outcomes. Our findings underscore the essential need for rigorous evaluations of clinical benefits, reinforced compliance with methodological standards, and balanced consideration of both benefits and harms to ensure meaningful integration into healthcare practice. This study did not receive any funding. ","10.1016/j.lanepe.2024.101145"
"PubMed","Green ILC: A Novel Energy-Efficient Iterative Learning Control Approach.","Yu Dou; Emmanuel Prempain","In this paper, we introduce Green Iterative Learning Control (Green ILC), an innovative hybrid control method that addresses the critical need for energy-efficient control in dynamic, repetitive-task environments. By integrating the iterative refinement capabilities of traditional Iterative Learning Control (ILC) with the optimization strengths of gradient descent, Green ILC achieves a balanced trade-off between tracking accuracy and energy consumption. This novel approach introduces a cost function that minimizes both tracking errors and control effort, enabling the system to adaptively optimize performance over iterations. Theoretical analysis and simulation results demonstrate that Green ILC not only achieves faster convergence but also provides significant energy savings compared with traditional ILC methods. Notably, Green ILC reduces energy consumption by prioritizing efficiency, making it particularly suitable for energy-intensive applications such as robotics, manufacturing, and process control. While a slight decrease in tracking accuracy is observed, this trade-off is acceptable for scenarios where energy efficiency is paramount. This work establishes Green ILC as a promising solution for modern industrial systems requiring robust and sustainable control strategies. ","10.3390/s24237787"
"PubMed","Drivable path detection for a mobile robot with differential drive using a deep Learning based segmentation method for indoor navigation.","Oğuz Mısır","The integration of artificial intelligence into the field of robotics enables robots to perform their tasks more meaningfully. In particular, deep-learning methods contribute significantly to robots becoming intelligent cybernetic systems. The effective use of deep-learning mobile cyber-physical systems has enabled mobile robots to become more intelligent. This effective use of deep learning can also help mobile robots determine a safe path. The drivable pathfinding problem involves a mobile robot finding the path to a target in a challenging environment with obstacles. In this paper, a semantic-segmentation-based drivable path detection method is presented for use in the indoor navigation of mobile robots. The proposed method uses a perspective transformation strategy based on transforming high-accuracy segmented images into real-world space. This transformation enables the motion space to be divided into grids, based on the image perceived in a real-world space. A grid-based RRT* navigation strategy was developed that uses images divided into grids to enable the mobile robot to avoid obstacles and meet the optimal path requirements. Smoothing was performed to improve the path planning of the grid-based RRT* and avoid unnecessary turning angles of the mobile robot. Thus, the mobile robot could reach the target in an optimum manner in the drivable area determined by segmentation. Deeplabv3+ and ResNet50 backbone architecture with superior segmentation ability are proposed for accurate determination of drivable path. Gaussian filter was used to reduce the noise caused by segmentation. In addition, multi-otsu thresholding was used to improve the masked images in multiple classes. The segmentation model and backbone architecture were compared in terms of their performance using different methods. DeepLabv3+ and ResNet50 backbone architectures outperformed the other compared methods by 0.21%-4.18% on many metrics. In addition, a mobile robot design is presented to test the proposed drivable path determination method. This design validates the proposed method by using different scenarios in an indoor environment. ","10.7717/peerj-cs.2514"
"PubMed","Exploring diabetes through the lens of AI and computer vision: Methods and future prospects.","Ramesh Chundi; Sasikala G; Praveen Kumar Basivi; Anitha Tippana; Vishwanath R Hulipalled; Prabakaran N; Jay B Simha; Chang Woo Kim; Vijay Kakani; Visweswara Rao Pasupuleti","Early diagnosis and timely initiation of treatment plans for diabetes are crucial for ensuring individuals' well-being. Emerging technologies like artificial intelligence (AI) and computer vision are highly regarded for their ability to enhance the accessibility of large datasets for dynamic training and deliver efficient real-time intelligent technologies and predictable models. The application of AI and computer vision techniques to enhance the analysis of clinical data is referred to as eHealth solutions that employ advanced approaches to aid medical applications. This study examines several advancements and applications of machine learning, deep learning, and machine vision in global perception, with a focus on sustainability. This article discusses the significance of utilizing artificial intelligence and computer vision to detect diabetes, as it has the potential to significantly mitigate harm to human life. This paper provides several comments addressing challenges and recommendations for the use of this technology in the field of diabetes. This study explores the potential of employing Industry 4.0 technologies, including machine learning, deep learning, and computer vision robotics, as effective tools for effectively dealing with diabetes related aspects. ","10.1016/j.compbiomed.2024.109537"
"PubMed","Editorial: Autonomous (re)production, learning and bio-inspired robotics workshop.","Andy M Tyrrell; Emma Hart; Alan Winfield; A E Eiben; Jon Timmis","","10.3389/frobt.2024.1513495"
"PubMed","AI-Powered Multimodal Modeling of Personalized Hemodynamics in Aortic Stenosis.","Caglar Ozturk; Daniel H Pak; Luca Rosalia; Debkalpa Goswami; Mary E Robakowski; Raymond McKay; Christopher T Nguyen; James S Duncan; Ellen T Roche","Aortic stenosis (AS) is the most common valvular heart disease in developed countries. High-fidelity preclinical models can improve AS management by enabling therapeutic innovation, early diagnosis, and tailored treatment planning. However, their use is currently limited by complex workflows necessitating lengthy expert-driven manual operations. Here, we propose an AI-powered computational framework for accelerated and democratized patient-specific modeling of AS hemodynamics from computed tomography (CT). First, we demonstrate that the automated meshing algorithms can generate task-ready geometries for both computational and benchtop simulations with higher accuracy and 100 times faster than existing approaches. Then, we show that the approach can be integrated with fluid-structure interaction and soft robotics models to accurately recapitulate a broad spectrum of clinical hemodynamic measurements of diverse AS patients. The efficiency and reliability of these algorithms make them an ideal complementary tool for personalized high-fidelity modeling of AS biomechanics, hemodynamics, and treatment planning. ","10.1002/advs.202404755"
"PubMed","Editorial: Human-robot collaboration in Industry 5.0: a human-centric AI-based approach.","Loris Roveda","","10.3389/frobt.2024.1511126"
"PubMed","A novel dataset of annotated oyster mushroom images with environmental context for machine learning applications.","Sonay Duman; Abdullah Elewi; Abdulsalam Hajhamed; Rasheed Khankan; Amina Souag; Asma Ahmed","State-of-the-art technologies such as computer vision and machine learning, are revolutionizing the smart mushroom industry by addressing diverse challenges in yield prediction, growth analysis, mushroom classification, disease and deformation detection, and digital twinning. However, mushrooms have long presented a challenge to automated systems due to their varied sizes, shapes, and surface characteristics, limiting the effectiveness of technologies aimed at mushroom classification and growth analysis. Clean and well-labelled datasets are therefore a cornerstone for developing efficient machine-learning models. Bridging this gap in oyster mushroom cultivation, we present a novel dataset comprising 555 high-quality camera raw images, from which approximately 16.000 manually annotated images were extracted. These images capture mushrooms in various shapes, maturity stages, and conditions, photographed in a greenhouse using two cameras for comprehensive coverage. Alongside the images, we recorded key environmental parameters within the mushroom greenhouse, such as temperature, relative humidity, moisture, and air quality, for a holistic analysis. This dataset is unique in providing both visual and environmental time-point data, organized into four storage folders: ""Raw Images""; ""Mushroom Labelled Images and Annotation Files""; ""Maturity Labelled Images and Annotation Files""; and ""Sensor Data"", which includes time-stamped sensor readings in Excel files. This dataset can enable researchers to develop high-quality prediction and classification machine learning models for the intelligent cultivation of oyster mushrooms. Beyond mushroom cultivation, this dataset also has the potential to be utilized in the fields of computer vision, artificial intelligence, robotics, precision agriculture, and fungal studies in general. ","10.1016/j.dib.2024.111074"
"PubMed","Integrating Historical Learning and Multi-View Attention with Hierarchical Feature Fusion for Robotic Manipulation.","Gaoxiong Lu; Zeyu Yan; Jianing Luo; Wei Li","Humans typically make decisions based on past experiences and observations, while in the field of robotic manipulation, the robot's action prediction often relies solely on current observations, which tends to make robots overlook environmental changes or become ineffective when current observations are suboptimal. To address this pivotal challenge in robotics, inspired by human cognitive processes, we propose our method which integrates historical learning and multi-view attention to improve the performance of robotic manipulation. Based on a spatio-temporal attention mechanism, our method not only combines observations from current and past steps but also integrates historical actions to better perceive changes in robots' behaviours and their impacts on the environment. We also employ a mutual information-based multi-view attention module to automatically focus on valuable perspectives, thereby incorporating more effective information for decision-making. Furthermore, inspired by human visual system which processes both global context and local texture details, we have devised a method that merges semantic and texture features, aiding robots in understanding the task and enhancing their capability to handle fine-grained tasks. Extensive experiments in RLBench and real-world scenarios demonstrate that our method effectively handles various tasks and exhibits notable robustness and adaptability. ","10.3390/biomimetics9110712"
"PubMed","Compassionate Care with Autonomous AI Humanoid Robots in Future Healthcare Delivery: A Multisensory Simulation of Next-Generation Models.","Joannes Paulus Tolentino Hernandez","The integration of AI and robotics in healthcare raises concerns, and additional issues regarding autonomous systems are anticipated. Effective communication is crucial for robots to be seen as ""caring"", necessitating advanced mechatronic design and natural language processing (NLP). This paper examines the potential of humanoid robots to autonomously replicate compassionate care. The study employs computational simulations using mathematical and agent-based modeling to analyze human-robot interactions (HRIs) surpassing Tetsuya Tanioka's TRETON. It incorporates stochastic elements (through neuromorphic computing) and quantum-inspired concepts (through the lens of Martha Rogers' theory), running simulations over 100 iterations to analyze complex behaviors. Multisensory simulations (visual and audio) demonstrate the significance of ""dynamic communication"", (relational) ""entanglement"", and (healthcare system and robot's function) ""superpositioning"" in HRIs. Quantum and neuromorphic computing may enable humanoid robots to empathetically respond to human emotions, based on Jean Watson's ten caritas processes for creating transpersonal states. Autonomous AI humanoid robots will redefine the norms of ""caring"". Establishing ""pluralistic agreements"" through open discussions among stakeholders worldwide is necessary to align innovations with the values of compassionate care within a ""posthumanist"" framework, where the compassionate care provided by Level 4 robots meets human expectations. Achieving compassionate care with autonomous AI humanoid robots involves translating nursing, communication, computer science, and engineering concepts into robotic care representations while considering ethical discourses through collaborative efforts. Nurses should lead the design and implementation of AI and robots guided by ""technological knowing"" in Rozzano Locsin's TCCN theory. ","10.3390/biomimetics9110687"
"PubMed","Analysis of Gender Issues in Computational Thinking Approach in Science and Mathematics Learning in Higher Education.","Alejandro De la Hoz Serrano; Lina Viviana Melo Niño; Andrés Álvarez Murillo; Miguel Ángel Martín Tardío; Florentina Cañada Cañada; Javier Cubero Juánez","In the contemporary era, Computational Thinking has emerged as a crucial skill for individuals to possess in order to thrive in the 21st century. In this context, there is a need to develop a methodology for cultivating these skills within a science and mathematics content education framework, particularly among pre-service teachers. This study aimed to investigate the impact of Educational Robotics on the development of Computational Thinking skills, with a particular focus on the role of gender, through a scientific and mathematical content teaching approach. A pre-experimental design with a quantitative approach was employed, and it was implemented with a total of 116 pre-service teachers, 38 males and 78 females. The results demonstrated a notable enhancement between the pre-test (8.11) and post-test (9.63) scores, emphasising specific concepts such as simple functions, while, and compound conditional. With respect to gender, statistically significant differences were identified prior to the intervention, but not following its implementation. The high level of Computational Thinking exhibited by both genders was comparable (53.85% in females and 55.26% in males) following the intervention. This indicates that the intervention is a promising approach for enhancing Computational Thinking proficiency, independent of gender and initial proficiency levels. The implementation of Educational Robotics in the teaching of science and mathematics enables the enhancement of Computational Thinking abilities among pre-service teachers, while reducing the observed gender disparity in this area of skill development. ","10.3390/ejihpe14110188"
"PubMed","Integrating AI into Breast Reconstruction Surgery: Exploring Opportunities, Applications, and Challenges.","Andrew Gorgy; Hong Hao Xu; Hassan El Hawary; Hillary Nepon; James Lee; Joshua Vorstenbosch","Background: Artificial intelligence (AI) has significantly influenced various sectors, including healthcare, by enhancing machine capabilities in assisting with human tasks. In surgical fields, where precision and timely decision-making are crucial, AI's integration could revolutionize clinical quality and health resource optimization. This study explores the current and future applications of AI technologies in reconstructive breast surgery, aiming for broader implementation. Methods: We conducted systematic reviews through PubMed, Web of Science, and Google Scholar using relevant keywords and MeSH terms. The focus was on the main AI subdisciplines: machine learning, computer vision, natural language processing, and robotics. This review includes studies discussing AI applications across preoperative, intraoperative, postoperative, and academic settings in breast plastic surgery. Results: AI is currently utilized preoperatively to predict surgical risks and outcomes, enhancing patient counseling and informed consent processes. During surgery, AI supports the identification of anatomical landmarks and dissection strategies and provides 3-dimensional visualizations. Robotic applications are promising for procedures like microsurgical anastomoses, flap harvesting, and dermal matrix anchoring. Postoperatively, AI predicts discharge times and customizes follow-up schedules, which improves resource allocation and patient management at home. Academically, AI offers personalized training feedback to surgical trainees and aids research in breast reconstruction. Despite these advancements, concerns regarding privacy, costs, and operational efficacy persist and are critically examined in this review. Conclusions: The application of AI in breast plastic and reconstructive surgery presents substantial benefits and diverse potentials. However, much remains to be explored and developed. This study aims to consolidate knowledge and encourage ongoing research and development within the field, thereby empowering the plastic surgery community to leverage AI technologies effectively and responsibly for advancing breast reconstruction surgery. ","10.1177/22925503241292349"
"PubMed","Nature redux: interrogating biomorphism and soft robot aesthetics through generative AI.","Mads Bering Christiansen; Ahmad Rafsanjani; Jonas Jørgensen","Artificial Intelligence (AI) has rapidly become a widespread design aid through the recent proliferation of generative AI tools. In this work we use generative AI to explore soft robotics designs, specifically Soft Biomorphism, an aesthetic design paradigm emphasizing the inherent biomorphic qualities of soft robots to leverage them as affordances for interactions with humans. The work comprises two experiments aimed at uncovering how generative AI can articulate and expand the design space of soft biomorphic robotics using text-to-image (TTI) and image-to-image (ITI) generation techniques. Through TTI generation, Experiment 1 uncovered alternative interpretations of soft biomorphism, emphasizing the novel incorporation of, e.g., fur, which adds a new dimension to the material aesthetics of soft robotics. In Experiment 2, TTI and ITI generation were combined and a category of hybrid techno-organic robot designs discovered, which combined rigid and pliable materials. The work thus demonstrates in practice the specific ways in which AI image generation can contribute towards expanding the design space of soft robotics. ","10.3389/frobt.2024.1472051"
"PubMed","Deep Learning: A Primer for Neurosurgeons.","Hongxi Yang; Chang Yuwen; Xuelian Cheng; Hengwei Fan; Xin Wang; Zongyuan Ge","This chapter explores the transformative impact of deep learning (DL) on neurosurgery, elucidating its pivotal role in enhancing diagnostic performance, surgical planning, execution, and postoperative assessment. It delves into various deep learning architectures, including convolutional and recurrent neural networks, and their applications in analyzing neuroimaging data for brain tumors, spinal cord injuries, and other neurological conditions. The integration of DL in neurosurgical robotics and the potential for fully autonomous surgical procedures are discussed, highlighting advancements in surgical precision and patient outcomes. The chapter also examines the challenges of data privacy, quality, and interpretability that accompany the implementation of DL in neurosurgery. The potential for DL to revolutionize neurosurgical practices through improved diagnostics, patient-specific surgical planning, and the advent of intelligent surgical robots is underscored, promising a future where technology and healthcare converge to offer unprecedented solutions in neurosurgery. ","10.1007/978-3-031-64892-2_4"
"PubMed","Towards industry-ready additive manufacturing: AI-enabled closed-loop control for 3D melt electrowriting.","Pawel Mieszczanek; Peter Corke; Courosh Mehanian; Paul D Dalton; Dietmar W Hutmacher","Melt electrowriting (MEW) is an emerging high-resolution 3D printing technology used in biomedical engineering, regenerative medicine, and soft robotics. Its transition from academia to industry faces challenges such as slow experimentation, low printing throughput, poor reproducibility, and user-dependent operation, largely due to the nonlinear and multiparametric nature of the MEW process. To address these challenges, we applied computer vision and machine learning to monitor and analyze the process in real-time through imaging of the MEW jet between the nozzle-collector gap. To collect data for training we developed an automated data collection methodology that eases the experimental time from days to hours. A feedforward neural network, working in concert with optimization methods and a feedback loop, is used to develop closed-loop control ensuring reproducibility of the printed parts. We demonstrate that machine learning allows streamlining the MEW operation via closed-loop control of the highly nonlinear 3D printing technology. ","10.1038/s44172-024-00302-4"
"PubMed","Capturing forceful interaction with deformable objects using a deep learning-powered stretchable tactile array.","Chunpeng Jiang; Wenqiang Xu; Yutong Li; Zhenjun Yu; Longchun Wang; Xiaotong Hu; Zhengyi Xie; Qingkun Liu; Bin Yang; Xiaolin Wang; Wenxin Du; Tutian Tang; Dongzhe Zheng; Siqiong Yao; Cewu Lu; Jingquan Liu","Capturing forceful interaction with deformable objects during manipulation benefits applications like virtual reality, telemedicine, and robotics. Replicating full hand-object states with complete geometry is challenging because of the occluded object deformations. Here, we report a visual-tactile recording and tracking system for manipulation featuring a stretchable tactile glove with 1152 force-sensing channels and a visual-tactile joint learning framework to estimate dynamic hand-object states during manipulation. To overcome the strain interference caused by contact with deformable objects, an active suppression method based on symmetric response detection and adaptive calibration is proposed and achieves 97.6% accuracy in force measurement, contributing to an improvement of 45.3%. The learning framework processes the visual-tactile sequence and reconstructs hand-object states. We experiment on 24 objects from 6 categories including both deformable and rigid ones with an average reconstruction error of 1.8 cm for all sequences, demonstrating a universal ability to replicate human knowledge in manipulating objects with varying degrees of deformability. ","10.1038/s41467-024-53654-y"
"PubMed","Leveraging imitation learning in agricultural robotics: a comprehensive survey and comparative analysis.","Siavash Mahmoudi; Amirreza Davar; Pouya Sohrabipour; Ramesh Bahadur Bist; Yang Tao; Dongyi Wang","Imitation learning (IL), a burgeoning frontier in machine learning, holds immense promise across diverse domains. In recent years, its integration into robotics has sparked significant interest, offering substantial advancements in autonomous control processes. This paper presents an exhaustive insight focusing on the implementation of imitation learning techniques in agricultural robotics. The survey rigorously examines varied research endeavors utilizing imitation learning to address pivotal agricultural challenges. Methodologically, this survey comprehensively investigates multifaceted aspects of imitation learning applications in agricultural robotics. The survey encompasses the identification of agricultural tasks that can potentially be addressed through imitation learning, detailed analysis of specific models and frameworks, and a thorough assessment of performance metrics employed in the surveyed studies. Additionally, it includes a comparative analysis between imitation learning techniques and conventional control methodologies in the realm of robotics. The findings derived from this survey unveil profound insights into the applications of imitation learning in agricultural robotics. These methods are highlighted for their potential to significantly improve task execution in dynamic and high-dimensional action spaces prevalent in agricultural settings, such as precision farming. Despite promising advancements, the survey discusses considerable challenges in data quality, environmental variability, and computational constraints that IL must overcome. The survey also addresses the ethical and social implications of implementing such technologies, emphasizing the need for robust policy frameworks to manage the societal impacts of automation. These findings hold substantial implications, showcasing the potential of imitation learning to revolutionize processes in agricultural robotics. This research significantly contributes to envisioning innovative applications and tools within the agricultural robotics domain, promising heightened productivity and efficiency in robotic agricultural systems. It underscores the potential for remarkable enhancements in various agricultural processes, signaling a transformative trajectory for the sector, particularly in the realm of robotics and autonomous systems. ","10.3389/frobt.2024.1441312"
"PubMed","Medical Doctors' Perceptions of Artificial Intelligence (AI) in Healthcare.","Arijita Banerjee; Pradosh Kumar Sarangi; Sumit Kumar","Introduction With the current exponential expansion of robotics, implants, and imaging technologies, diagnostic processes within the healthcare industry are becoming popular platforms for artificial intelligence (AI) use. Thus, an understanding of physicians' attitudes toward AI and the extent to which medical educators are ready to work with AI is necessary. This research aimed to study doctors' perceptions of AI in healthcare. Methods A web-based questionnaire organized into four sections, namely, demographics, concepts of AI, education in AI, and implementation challenges related to AI, was designed systematically based on a literature search and circulated among medical doctors from various fields. Results Study participants exhibited a lower score toward familiarity with AI. Only 52.12% (74/142) of physicians completed the survey. The greatest challenge associated with the use of AI in therapeutic settings was found to be the degree of autonomy, with a score of 3.56. Among the participants, 67.61% felt that the lack of human supervision was the most important limiting factor in the implementation of AI in clinical practice. However, the participants demonstrated a strong interest in understanding the concepts of AI in the near future. Conclusion This study revealed a low degree of familiarity with AI, highlighting the need for medical schools and hospitals to establish specialized education and training programs for physicians to improve patient outcomes. ","10.7759/cureus.70508"
"PubMed","Targeted weed management of Palmer amaranth using robotics and deep learning (YOLOv7).","Amlan Balabantaray; Shaswati Behera; CheeTown Liew; Nipuna Chamara; Mandeep Singh; Amit J Jhala; Santosh Pitla","Effective weed management is a significant challenge in agronomic crops which necessitates innovative solutions to reduce negative environmental impacts and minimize crop damage. Traditional methods often rely on indiscriminate herbicide application, which lacks precision and sustainability. To address this critical need, this study demonstrated an AI-enabled robotic system, Weeding robot, designed for targeted weed management. Palmer amaranth (Amaranthus palmeri S. Watson) was selected as it is the most troublesome weed in Nebraska. We developed the full stack (vision, hardware, software, robotic platform, and AI model) for precision spraying using YOLOv7, a state-of-the-art object detection deep learning technique. The Weeding robot achieved an average of 60.4% precision and 62% recall in real-time weed identification and spot spraying with the developed gantry-based sprayer system. The Weeding robot successfully identified Palmer amaranth across diverse growth stages in controlled outdoor conditions. This study demonstrates the potential of AI-enabled robotic systems for targeted weed management, offering a more precise and sustainable alternative to traditional herbicide application methods. ","10.3389/frobt.2024.1441371"
"PubMed","AI security and cyber risk in IoT systems.","Petar Radanliev; David De Roure; Carsten Maple; Jason R C Nurse; Razvan Nicolescu; Uchenna Ani","Internet-of-Things (IoT) refers to low-memory connected devices used in various new technologies, including drones, autonomous machines, and robotics. The article aims to understand better cyber risks in low-memory devices and the challenges in IoT risk management. The article includes a critical reflection on current risk methods and their level of appropriateness for IoT. We present a dependency model tailored in context toward current challenges in data strategies and make recommendations for the cybersecurity community. The model can be used for cyber risk estimation and assessment and generic risk impact assessment. The model is developed for cyber risk insurance for new technologies (e.g., drones, robots). Still, practitioners can apply it to estimate and assess cyber risks in organizations and enterprises. Furthermore, this paper critically discusses why risk assessment and management are crucial in this domain and what open questions on IoT risk assessment and risk management remain areas for further research. The paper then presents a more holistic understanding of cyber risks in the IoT. We explain how the industry can use new risk assessment, and management approaches to deal with the challenges posed by emerging IoT cyber risks. We explain how these approaches influence policy on cyber risk and data strategy. We also present a new approach for cyber risk assessment that incorporates IoT risks through dependency modeling. The paper describes why this approach is well suited to estimate IoT risks. ","10.3389/fdata.2024.1402745"
"PubMed","Attention Induced Dual Convolutional-Capsule Network (AIDC-CN): A deep learning framework for motor imagery classification.","Ritesh Sur Chowdhury; Shirsha Bose; Sayantani Ghosh; Amit Konar","In recent times, Electroencephalography (EEG)-based motor imagery (MI) decoding has garnered significant attention due to its extensive applicability in healthcare, including areas such as assistive robotics and rehabilitation engineering. Nevertheless, the decoding of EEG signals presents considerable challenges owing to their inherent complexity, non-stationary characteristics, and low signal-to-noise ratio. Notably, deep learning-based classifiers have emerged as a prominent focus for addressing the EEG signal decoding process. This study introduces a novel deep learning classifier named the Attention Induced Dual Convolutional-Capsule Network (AIDC-CN) with the specific aim of accurately categorizing various motor imagination class labels. To enhance the classifier's performance, a dual feature extraction approach leveraging spectrogram and brain connectivity networks has been employed, diversifying the feature set in the classification task. The main highlights of the proposed AIDC-CN classifier includes the introduction of a dual convolution layer to handle the brain connectivity and spectrogram features, addition of a novel self-attention module (SAM) to accentuate the relevant parts of the convolved spectrogram features, introduction of a new cross-attention module (CAM) to refine the outputs obtained from the dual convolution layers and incorporation of a Gaussian Error Linear Unit (GELU) based dynamic routing algorithm to strengthen the coupling among the primary and secondary capsule layers. Performance analysis undertaken on four public data sets depict the superior performance of the proposed model with respect to the state-of-the-art techniques. The code for this model is available at https://github.com/RiteshSurChowdhury/AIDC-CN. ","10.1016/j.compbiomed.2024.109260"
"PubMed","The balancing act: Adopting AI and robotics in medicine with cautious optimism.","Vaibhav Bagaria; Harvinder Singh Chhabra","","10.1016/j.jcot.2024.102550"
"PubMed","Classifying Residual Stroke Severity Using Robotics-Assisted Stroke Rehabilitation: Machine Learning Approach.","Russell Jeter; Raymond Greenfield; Stephen N Housley; Igor Belykh","Stroke therapy is essential to reduce impairments and improve motor movements by engaging autogenous neuroplasticity. Traditionally, stroke rehabilitation occurs in inpatient and outpatient rehabilitation facilities. However, recent literature increasingly explores moving the recovery process into the home and integrating technology-based interventions. This study advances this goal by promoting in-home, autonomous recovery for patients who experienced a stroke through robotics-assisted rehabilitation and classifying stroke residual severity using machine learning methods. Our main objective is to use kinematics data collected during in-home, self-guided therapy sessions to develop supervised machine learning methods, to address a clinician's autonomous classification of stroke residual severity-labeled data toward improving in-home, robotics-assisted stroke rehabilitation. In total, 33 patients who experienced a stroke participated in in-home therapy sessions using Motus Nova robotics rehabilitation technology to capture upper and lower body motion. During each therapy session, the Motus Hand and Motus Foot devices collected movement data, assistance data, and activity-specific data. We then synthesized, processed, and summarized these data. Next, the therapy session data were paired with clinician-informed, discrete stroke residual severity labels: ""no range of motion (ROM),"" ""low ROM,"" and ""high ROM."" Afterward, an 80%:20% split was performed to divide the dataset into a training set and a holdout test set. We used 4 machine learning algorithms to classify stroke residual severity: light gradient boosting (LGB), extra trees classifier, deep feed-forward neural network, and classical logistic regression. We selected models based on 10-fold cross-validation and measured their performance on a holdout test dataset using F1-score to identify which model maximizes stroke residual severity classification accuracy. We demonstrated that the LGB method provides the most reliable autonomous detection of stroke severity. The trained model is a consensus model that consists of 139 decision trees with up to 115 leaves each. This LGB model boasts a 96.70% F1-score compared to logistic regression (55.82%), extra trees classifier (94.81%), and deep feed-forward neural network (70.11%). We showed how objectively measured rehabilitation training paired with machine learning methods can be used to identify the residual stroke severity class, with efforts to enhance in-home self-guided, individualized stroke rehabilitation. The model we trained relies only on session summary statistics, meaning it can potentially be integrated into similar settings for real-time classification, such as outpatient rehabilitation facilities. ","10.2196/56980"
"PubMed","Reinforcement learning of biomimetic navigation: a model problem for sperm chemotaxis.","Omar Mohamed; Alan C H Tsang","Motile biological cells can respond to local environmental cues and exhibit various navigation strategies to search for specific targets. These navigation strategies usually involve tuning of key biophysical parameters of the cells, such that the cells can modulate their trajectories to move in response to the detected signals. Here we introduce a reinforcement learning approach to modulate key biophysical parameters and realize navigation strategies reminiscent to those developed by biological cells. We present this approach using sperm chemotaxis toward an egg as a paradigm. By modulating the trajectory curvature of a sperm cell model, the navigation strategies informed by reinforcement learning are capable to resemble sperm chemotaxis observed in experiments. This approach provides an alternative method to capture biologically relevant navigation strategies, which may inform the necessary parameter modulations required for obtaining specific navigation strategies and guide the design of biomimetic micro-robotics. ","10.1140/epje/s10189-024-00451-6"
"PubMed","Using Reinforcement Learning to Develop a Novel Gait for a Bio-Robotic California Sea Lion.","Anthony Drago; Shraman Kadapa; Nicholas Marcouiller; Harry G Kwatny; James L Tangorra","While researchers have made notable progress in bio-inspired swimming robot development, a persistent challenge lies in creating propulsive gaits tailored to these robotic systems. The California sea lion achieves its robust swimming abilities through a careful coordination of foreflippers and body segments. In this paper, reinforcement learning (RL) was used to develop a novel sea lion foreflipper gait for a bio-robotic swimmer using a numerically modelled computational representation of the robot. This model integration enabled reinforcement learning to develop desired swimming gaits in the challenging underwater domain. The novel RL gait outperformed the characteristic sea lion foreflipper gait in the simulated underwater domain. When applied to the real-world robot, the RL constructed novel gait performed as well as or better than the characteristic sea lion gait in many factors. This work shows the potential for using complimentary bio-robotic and numerical models with reinforcement learning to enable the development of effective gaits and maneuvers for underwater swimming vehicles. ","10.3390/biomimetics9090522"
"PubMed","Learning curves for adoption of robotic bariatric surgery: a systematic review of safety, efficiency and clinical outcomes.","Faith Hirri; Oliver J Pickering; Nicholas C Carter; Gijsbert I van Boxel; Philip H Pucher","Robotic bariatric surgery may overcome challenges associated with laparoscopy, potentially achieving technically superior results. This review aims to summarise current literature reporting on learning curves for surgeons newly adopting robotic bariatrics and implications for safety, efficiency and outcomes. A systematic review was performed in line with the PRISMA guidelines. Electronic databases PubMed and MEDLINE were searched and articles reporting on learning curves in robotic bariatric surgery were identified. Studies that reported changes in outcome over time, or learning curves for surgeons newly adopting robotic bariatric surgery were included in this review. Eleven studies reporting on 1237 patients were included in this review. Most surgeons reported prior bariatric surgical experience. Differences were noted regarding the approach and adoption of robotics. Ten studies found significant reduction in operative time, with the shortest learning curve of 11 cases. Reporting of clinical outcomes was limited. Three studies reported statistically significant improvement in outcomes after the learning curve. Long-term outcomes were in line with current literature, though none assessed differences between learning curve groups. Reported learning curves in robotic bariatric surgery is variable, with limited reporting of clinical outcomes. With appropriate mentorship, surgeons can improve efficiency, safety and clinical outcomes, maximising the benefits of minimally invasive surgery. ","10.1007/s11701-024-02100-8"
"PubMed","Reinforcement learning as a robotics-inspired framework for insect navigation: from spatial representations to neural implementation.","Stephan Lochner; Daniel Honerkamp; Abhinav Valada; Andrew D Straw","Bees are among the master navigators of the insect world. Despite impressive advances in robot navigation research, the performance of these insects is still unrivaled by any artificial system in terms of training efficiency and generalization capabilities, particularly considering the limited computational capacity. On the other hand, computational principles underlying these extraordinary feats are still only partially understood. The theoretical framework of reinforcement learning (RL) provides an ideal focal point to bring the two fields together for mutual benefit. In particular, we analyze and compare representations of space in robot and insect navigation models through the lens of RL, as the efficiency of insect navigation is likely rooted in an efficient and robust internal representation, linking retinotopic (egocentric) visual input with the geometry of the environment. While RL has long been at the core of robot navigation research, current computational theories of insect navigation are not commonly formulated within this framework, but largely as an associative learning process implemented in the insect brain, especially in the mushroom body (MB). Here we propose specific hypothetical components of the MB circuit that would enable the implementation of a certain class of relatively simple RL algorithms, capable of integrating distinct components of a navigation task, reminiscent of hierarchical RL models used in robot navigation. We discuss how current models of insect and robot navigation are exploring representations beyond classical, complete map-like representations, with spatial information being embedded in the respective latent representations to varying degrees. ","10.3389/fncom.2024.1460006"
"PubMed","Robotics in Arthroplasty: Historical Progression, Contemporary Applications, and Future Horizons With Artificial Intelligence (AI) Integration.","Jagbir Singh; Priyankkumar Patel","Robotic technology is increasingly utilized in surgical procedures to enhance precision, particularly in tasks demanding delicate maneuvers beyond human capabilities. Robotic orthopedic surgery emerges as a dynamic and compelling technology reshaping the landscape of surgical practice. This aids surgeons in achieving enhanced accuracy and reproducibility, ultimately aiming for improved patient outcomes. As of now, the majority of these systems are in a developed stage and are gradually gaining broader adoption. These systems have to show that they are user-friendly, are successful in clinical settings, and have a good cost-effectiveness ratio before they can be widely adopted in the field of surgery. In this review, we examine the evolution of robotics in orthopedic surgery, assess its current applications, and provide insights into the future trajectory of this technology, particularly in light of advances in artificial intelligence (AI) and machine learning (ML). ","10.7759/cureus.67611"
